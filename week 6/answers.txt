6.1
	1. It does deadlock since both threads are waiting for the other to unlock the balance variable.
	2. It doesn't lock up after running ~20 times
	3. It does not deadlock and compiles.
	4. The reason to not take all three locks is that it would mean that every single transfer call would have to wait for the tielock to be lifted. Meaning that it would in the end essentially be sequential, rendering the multi-threading obsolete.

6.2 
	1. Since every fork is shared between two philosophers on either side, a deadlock could occur if a philosopher (p1) acquires a lock on his left fork while p2 already has a lock on his left fork, block p1 from taking his right. This could then go all around the table meaning that everyone has a lock on a single fork, waiting for the other to get released.
	2. My times varied quite a bit. I had an almost instantaneous lock, but also one thta ran for a good 10 minutes without ever locking up.
	3. 
		"Thread-4":
		  waiting to lock monitor 0x0000000018cc6fc8 (object 0x0000000795f65208, a Fork),
		  which is held by "Thread-0"
		"Thread-0":
		  waiting to lock monitor 0x0000000017395728 (object 0x0000000795f65218, a Fork),
		  which is held by "Thread-1"
		"Thread-1":
		  waiting to lock monitor 0x0000000018cc8518 (object 0x0000000795f65228, a Fork),
		  which is held by "Thread-2"
		"Thread-2":
		  waiting to lock monitor 0x0000000018cc8468 (object 0x0000000795f65238, a Fork),
		  which is held by "Thread-3"
		"Thread-3":
		  waiting to lock monitor 0x0000000017393208 (object 0x0000000795f65248, a Fork),
		  which is held by "Thread-4"

		So as mentioned in answer 1, each philosopher has a lock on one fork, having everybody wait for the release of their other.

	4. I've put a static sequence number on the fork class, which i increment on every construction, and allow to proceed if left is lower than right. 

	5. Yes all philosophers get to eat.

	6. It does not seem to be a fair distribution. It did have p0 lack behind quite a bit and p3 was for the most part on a gorging spree. This kept on happening and at around the 40th iteration the difference was ~3000 between highest and lowest. The other times that I ran it the results were completely different. I mosty expect that it's some rythm that a certain thread may fall in to that allows it to eat on every pass through, and has minimal waiting time. Something that i was considering though was that it should even out eventually, but the disparity just kept increasing.


6.4
	1. The initial test threadsafe did not complain. When removing all the synchronized keywords it starts complaining that the reads/writes of counts is not synchronized. It does not expect getSpan() to be synchronized since it doesn't look at anything but the array length that is not tampered with by any threads anyway.
		
	2. Threadsafe wants the counts operation where I add the hist count. Since the counts member is the only thing that is @GuardedBy threadsafe. 

	3. Threadsafe gives a Sometimes Synchronized read message. I would say that there is room for worry. While the addAll() method is synchronized, meaning that it will lock its own counts member. However, the incoming hist.counts will not be locked rendering it non threadsafe.